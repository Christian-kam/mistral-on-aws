{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5102bd3-af3f-4786-86af-16275bb99b74",
   "metadata": {},
   "source": [
    "# Workshop3: Fine-tuning Mistral Small 24B with QLoRA\n",
    "\n",
    "Welcome to this hands-on workshop! By the end of this session, you'll have fine-tuned a Mistral Small 24B model for medical diagnosis and deployed it as a custom model in Amazon Bedrock.\n",
    "\n",
    "### What You'll Learn:\n",
    "- Fine-tuning large language models with QLoRA (Quantized LoRA)\n",
    "- Working with medical datasets for AI training\n",
    "- Preparing models for Amazon Bedrock Custom Model Import\n",
    "- Comparing base vs fine-tuned model performance\n",
    "\n",
    "### Prerequisites:\n",
    "- AWS account with Bedrock access\n",
    "- SageMaker Studio or similar GPU environment\n",
    "- Basic understanding of machine learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2de331-07f3-4de5-a4eb-16df0fa79a8b",
   "metadata": {},
   "source": [
    "## Workshop Overview:\n",
    "1. **Environment Setup** - Install dependencies and configure environment\n",
    "2. **Data Preparation** - Load and prepare medical training data\n",
    "3. **Model Loading** - Load quantized Mistral Small 24B model\n",
    "4. **QLoRA Configuration** - Set up efficient fine-tuning adapters\n",
    "5. **Training** - Fine-tune the model on medical data\n",
    "6. **Evaluation** - Compare base vs fine-tuned performance\n",
    "7. **Model Preparation** - Prepare for Bedrock deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81158e6b-4020-492e-8885-dd9b57b66314",
   "metadata": {},
   "source": [
    "<mark>Note: We don't fine-tune the model during the workshop. If you want to fine-tune the model later offline, recommended configurations are:</mark>\n",
    "- **Instance Type**: `ml.g5.48xlarge` or similar (8 A10G GPUs, 24GB GPU memory each)\n",
    "- **Alternative**: `ml.g6.16xlarge` (1 NVIDIA L4 GPUs, 24‚ÄØGB GPU memory) \n",
    "- **Environment**: SageMaker Studio with Python 3 kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa05520-efa8-41ef-a489-524d7d1c480b",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup & Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ea6b2-265d-4576-95bd-1b3ceb10fe3d",
   "metadata": {},
   "source": [
    "Let's start by setting up our environment and understanding our tools:\n",
    "\n",
    "### Dataset Information:\n",
    "We'll use the **BI55/MedText** dataset, which contains medical prompts and completions for training a medical AI assistant.\n",
    "\n",
    "### Hugging Face Setup:\n",
    "1. Get access to [Mistral Small 24B Instruct](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501)\n",
    "2. Create a [Hugging Face API token](https://huggingface.co/docs/hub/en/security-tokens) with READ permissions\n",
    "3. Login using `notebook_login()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e6ba31-44da-4a36-89b8-955d3a4d829a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:52:44.936849Z",
     "iopub.status.busy": "2025-06-13T13:52:44.936575Z",
     "iopub.status.idle": "2025-06-13T13:52:45.070594Z",
     "shell.execute_reply": "2025-06-13T13:52:45.070179Z",
     "shell.execute_reply.started": "2025-06-13T13:52:44.936833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129751c9a0154991805fa08578f7b7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e671e58d-5bd8-41eb-8e1d-a77194c62eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:54:05.548651Z",
     "iopub.status.busy": "2025-06-13T13:54:05.548490Z",
     "iopub.status.idle": "2025-06-13T13:54:05.550890Z",
     "shell.execute_reply": "2025-06-13T13:54:05.550482Z",
     "shell.execute_reply.started": "2025-06-13T13:54:05.548635Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5cc7d-823b-4dfd-a1a9-80812a83ac42",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aeeeb01-e2df-4e20-8b4a-a26d9ddb0964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:52:58.143222Z",
     "iopub.status.busy": "2025-06-13T13:52:58.142530Z",
     "iopub.status.idle": "2025-06-13T13:54:05.485940Z",
     "shell.execute_reply": "2025-06-13T13:54:05.485359Z",
     "shell.execute_reply.started": "2025-06-13T13:52:58.143186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.3.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "autogluon-multimodal 1.3.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.51.3 which is incompatible.\n",
      "autogluon-timeseries 1.3.0 requires coreforecast<0.0.16,>=0.0.12, but you have coreforecast 0.0.16 which is incompatible.\n",
      "autogluon-timeseries 1.3.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.51.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.2.4 requires onnxruntime<2,>=1.15.0, which is not installed.\n",
      "autogluon-multimodal 1.3.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "autogluon-multimodal 1.3.0 requires torch<2.7,>=2.2, but you have torch 2.7.1 which is incompatible.\n",
      "autogluon-timeseries 1.3.0 requires coreforecast<0.0.16,>=0.0.12, but you have coreforecast 0.0.16 which is incompatible.\n",
      "autogluon-timeseries 1.3.0 requires torch<2.7,>=2.2, but you have torch 2.7.1 which is incompatible.\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -qU accelerate>=1.6.0\n",
    "!pip3 install -qU torch bitsandbytes transformers==4.46.3 peft datasets\n",
    "!pip3 install -qU tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d8b1cb-b09a-440a-8720-f7c330f134a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:54:05.551921Z",
     "iopub.status.busy": "2025-06-13T13:54:05.551634Z",
     "iopub.status.idle": "2025-06-13T13:54:05.556210Z",
     "shell.execute_reply": "2025-06-13T13:54:05.555850Z",
     "shell.execute_reply.started": "2025-06-13T13:54:05.551907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add installed cuda runtime to path for bitsandbytes \n",
    "import nvidia\n",
    "import os\n",
    "\n",
    "cuda_install_dir = '/'.join(nvidia.__file__.split('/')[:-1]) + '/cuda_runtime/lib/'\n",
    "os.environ['LD_LIBRARY_PATH'] =  cuda_install_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e4f3f-fd60-4b44-807a-defbc5b258a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:25:28.980761Z",
     "iopub.status.busy": "2025-06-13T11:25:28.980491Z",
     "iopub.status.idle": "2025-06-13T11:25:28.983043Z",
     "shell.execute_reply": "2025-06-13T11:25:28.982691Z",
     "shell.execute_reply.started": "2025-06-13T11:25:28.980747Z"
    }
   },
   "source": [
    "## Step 2: Load and Prepare Medical Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160fa98f-fb15-4a92-b2d2-bf335b40fc91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:54:05.556888Z",
     "iopub.status.busy": "2025-06-13T13:54:05.556608Z",
     "iopub.status.idle": "2025-06-13T13:54:08.944234Z",
     "shell.execute_reply": "2025-06-13T13:54:08.943762Z",
     "shell.execute_reply.started": "2025-06-13T13:54:05.556874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• Loading medical dataset...\n",
      "‚úÖ Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the medical dataset and split into train/validation/test sets\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "print(\"üè• Loading medical dataset...\")\n",
    "dataset = load_dataset(\"BI55/MedText\", split=\"train\")\n",
    "\n",
    "# Split into 80% train, 10% validation, 10% test\n",
    "split_1 = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "split_2 = split_1['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "train_set = split_1['train']\n",
    "validation_set = split_2['train']\n",
    "test_set = split_2['test']\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b8b015-1619-45d1-87f3-dbe3787ca7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:16.881193Z",
     "iopub.status.busy": "2025-06-13T13:58:16.880858Z",
     "iopub.status.idle": "2025-06-13T13:58:16.884704Z",
     "shell.execute_reply": "2025-06-13T13:58:16.884289Z",
     "shell.execute_reply.started": "2025-06-13T13:58:16.881178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset structure:\n",
      "   Features: {'Prompt': Value(dtype='string', id=None), 'Completion': Value(dtype='string', id=None)}\n",
      "\n",
      "üìã Sample data point:\n",
      "   Prompt: A 16-year-old male presents with multiple blackheads and red bumps on his forehead, cheeks, and nose. He mentions they have been persisting for about a year, and he feels his skin is quite oily. What could be the potential cause, and what would be the treatment plan?\n",
      "   Completion: This patient is likely suffering from moderate acne vulgaris, characterized by a mix of open comedones (blackheads) and inflammatory lesions (red bumps). Acne vulgaris is common during adolescence due to increased sebum production, prompted by hormonal changes. The first line of treatment includes topical retinoids, which help unclog pores, and topical antimicrobials such as benzoyl peroxide or clindamycin to reduce bacterial growth and inflammation.\n"
     ]
    }
   ],
   "source": [
    "# Let's examine our dataset structure\n",
    "print(\"üîç Dataset structure:\")\n",
    "print(f\"   Features: {train_set.features}\")\n",
    "print(f\"\\nüìã Sample data point:\")\n",
    "print(f\"   Prompt: {train_set[0]['Prompt']}\")\n",
    "print(f\"   Completion: {train_set[0]['Completion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb25309-c886-49f3-bee8-8b4e4cf5f707",
   "metadata": {},
   "source": [
    "## Step 3: Load Quantized Mistral Small 24B Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898c64bc-f691-4b85-828c-f1450b02bc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T12:58:15.222159Z",
     "iopub.status.busy": "2025-06-13T12:58:15.221467Z",
     "iopub.status.idle": "2025-06-13T12:58:33.285996Z",
     "shell.execute_reply": "2025-06-13T12:58:33.285525Z",
     "shell.execute_reply.started": "2025-06-13T12:58:15.222121Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading Mistral Small 24B model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 12:58:16.934719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749819496.945856    2787 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749819496.949327    2787 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-13 12:58:16.961086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408a74acac1a4694809c0c8524e85f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the quantized model with 4-bit precision for efficient training\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "print(\"üöÄ Loading Mistral Small 24B model...\")\n",
    "model_id = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n",
    "\n",
    "# Configure 4-bit quantization for memory efficiency\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model with quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config, \n",
    "    device_map=\"auto\", \n",
    "    cache_dir=\"/home/sagemaker-user/model_cache\"  # Use NVMe storage for caching\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b567741c-5e7c-478c-aacf-11dcd1ad2f23",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T13:02:38.605474Z",
     "iopub.status.busy": "2025-06-13T13:02:38.604903Z",
     "iopub.status.idle": "2025-06-13T13:02:38.789522Z",
     "shell.execute_reply": "2025-06-13T13:02:38.788964Z",
     "shell.execute_reply.started": "2025-06-13T13:02:38.605457Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                             Size  Used Avail Use% Mounted on\n",
      "overlay                                 37G  5.3G   32G  15% /\n",
      "tmpfs                                   64M     0   64M   0% /dev\n",
      "tmpfs                                   61G     0   61G   0% /sys/fs/cgroup\n",
      "shm                                     16G   80K   16G   1% /dev/shm\n",
      "/dev/mapper/sagemaker_vg-sagemaker_lv  838G   50G  788G   6% /mnt/sagemaker-nvme\n",
      "/dev/nvme0n1p1                         180G   31G  150G  17% /usr/bin/nvidia-smi\n",
      "/dev/nvme3n1                           100G   49G   52G  49% /home/sagemaker-user\n",
      "127.0.0.1:/                            8.0E     0  8.0E   0% /mnt/custom-file-systems/efs/fs-09badb99b5c560bea_fsap-0c61ab2cee099341a\n",
      "tmpfs                                   61G   12K   61G   1% /proc/driver/nvidia\n",
      "tmpfs                                   61G  1.3M   61G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs                                   61G     0   61G   0% /proc/acpi\n",
      "tmpfs                                   61G     0   61G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee32c32-75a9-478b-838c-567c2272a78d",
   "metadata": {},
   "source": [
    "## Step 4: Tokenization and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d2bc9f-e1a3-4dc9-8ad2-ff7a2e9ef250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:04.511377Z",
     "iopub.status.busy": "2025-06-13T13:58:04.510998Z",
     "iopub.status.idle": "2025-06-13T13:58:04.523468Z",
     "shell.execute_reply": "2025-06-13T13:58:04.522899Z",
     "shell.execute_reply.started": "2025-06-13T13:58:04.511361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Loading tokenizer...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load tokenizer for text processing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müî§ Loading tokenizer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      4\u001b[0m     model_id, \n\u001b[1;32m      5\u001b[0m     add_eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,    \u001b[38;5;66;03m# End Of Sentence Token\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     add_bos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m     \u001b[38;5;66;03m# Beginning Of Sentence Token\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Tokenizer loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load tokenizer for text processing\n",
    "print(\"üî§ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    add_eos_token=True,    # End Of Sentence Token\n",
    "    add_bos_token=True     # Beginning Of Sentence Token\n",
    ")\n",
    "print(\"‚úÖ Tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1fd17-6497-4ea4-a783-660d8b1b5431",
   "metadata": {},
   "source": [
    "### Format Training Data\n",
    "We need to format our medical data with a consistent prompt template for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc879266-4973-48a4-9ffa-0e0f3dfb3204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:02:49.898091Z",
     "iopub.status.busy": "2025-06-13T13:02:49.897139Z",
     "iopub.status.idle": "2025-06-13T13:02:49.901034Z",
     "shell.execute_reply": "2025-06-13T13:02:49.900607Z",
     "shell.execute_reply.started": "2025-06-13T13:02:49.898043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(prompt):\n",
    "    result = tokenizer(prompt)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()   # Setting labels = input_ids for causal LM\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1cc27b-a86f-469c-bd7d-95c2cd441aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:02:52.622256Z",
     "iopub.status.busy": "2025-06-13T13:02:52.621603Z",
     "iopub.status.idle": "2025-06-13T13:02:52.624689Z",
     "shell.execute_reply": "2025-06-13T13:02:52.624312Z",
     "shell.execute_reply.started": "2025-06-13T13:02:52.622239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Format data with medical prompt template\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = f\"\"\"You are a medical professional. Given a prompt of a user with different symptoms, provide a diagnosis.\n",
    "\n",
    "    ### Prompt:\n",
    "    {data_point[\"Prompt\"]}\n",
    "    \n",
    "    ### Response:\n",
    "    {data_point[\"Completion\"]}\n",
    "    \"\"\"\n",
    "    return tokenize(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d34e4d-5dbb-4053-8f35-ecd0c79b27b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:02:54.922560Z",
     "iopub.status.busy": "2025-06-13T13:02:54.922058Z",
     "iopub.status.idle": "2025-06-13T13:02:55.725130Z",
     "shell.execute_reply": "2025-06-13T13:02:55.724371Z",
     "shell.execute_reply.started": "2025-06-13T13:02:54.922545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162e511b5b56499d8f80f91ac4309f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f232da8c939f45938e260d5886251133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/141 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Apply tokenization to our datasets\n",
    "print(\"üîÑ Tokenizing datasets...\")\n",
    "tokenized_train_dataset = train_set.map(generate_and_tokenize_prompt)\n",
    "tokenized_validation_dataset = validation_set.map(generate_and_tokenize_prompt)\n",
    "print(\"‚úÖ Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b18f0-2d21-4514-a2b4-af0298e79038",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Token Lengths & Set Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013828a-0252-438a-b7f7-5ae5acf8af33",
   "metadata": {},
   "source": [
    "### Visualize Token Length Distribution\n",
    "Understanding our data's token lengths helps us set appropriate padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1beab6-4100-4211-9de5-eb87a6520b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:02:58.106885Z",
     "iopub.status.busy": "2025-06-13T13:02:58.106507Z",
     "iopub.status.idle": "2025-06-13T13:02:58.111049Z",
     "shell.execute_reply": "2025-06-13T13:02:58.110307Z",
     "shell.execute_reply.started": "2025-06-13T13:02:58.106869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize token length distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_validation_dataset):\n",
    "    lengths1 = [len(x[\"input_ids\"]) for x in tokenized_train_dataset]\n",
    "    lengths2 = [len(x[\"input_ids\"]) for x in tokenized_validation_dataset]\n",
    "    lengths = lengths1 + lengths2\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color=\"blue\")\n",
    "    plt.xlabel(\"Token Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of Input Token Lengths\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìä Max token length: {max(lengths)}\")\n",
    "    print(f\"üìä Average token length: {sum(lengths)/len(lengths):.1f}\")\n",
    "    \n",
    "    return max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b12820-eacc-4444-ac2f-ff1bcf9d9718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:00.568887Z",
     "iopub.status.busy": "2025-06-13T13:03:00.568085Z",
     "iopub.status.idle": "2025-06-13T13:03:00.910627Z",
     "shell.execute_reply": "2025-06-13T13:03:00.910116Z",
     "shell.execute_reply.started": "2025-06-13T13:03:00.568842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Max token length: 257\n",
      "üìä Average token length: 166.1\n",
      "üéØ Using max length: 257 tokens\n"
     ]
    }
   ],
   "source": [
    "# Get maximum length and visualize distribution\n",
    "max_length = plot_data_lengths(tokenized_train_dataset, tokenized_validation_dataset)\n",
    "\n",
    "# Alternative: Direct calculation of max length\n",
    "# max_length = max([len(x[\"input_ids\"]) for x in tokenized_train_dataset])\n",
    "print(f\"üéØ Using max length: {max_length} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bdfc2-5b0d-47a2-9210-88591823ac4a",
   "metadata": {},
   "source": [
    "### Configure Tokenizer with Padding\n",
    "Now we'll set up padding to ensure all inputs are the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ad2d92-dd21-423b-a08e-12b94a0358e9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T13:57:53.153686Z",
     "iopub.status.busy": "2025-06-13T13:57:53.153278Z",
     "iopub.status.idle": "2025-06-13T13:57:53.246126Z",
     "shell.execute_reply": "2025-06-13T13:57:53.245464Z",
     "shell.execute_reply.started": "2025-06-13T13:57:53.153670Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reconfigure tokenizer with padding\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     model_id,\n\u001b[1;32m      4\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     add_eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     add_bos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token    \u001b[38;5;66;03m# Use EOS token as pad token\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Tokenizer configured with padding to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Reconfigure tokenizer with padding\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"right\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token    # Use EOS token as pad token\n",
    "\n",
    "print(f\"‚úÖ Tokenizer configured with padding to {max_length} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7016d8-9573-4ad0-bb94-23d87cd902a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:08.400267Z",
     "iopub.status.busy": "2025-06-13T13:03:08.399889Z",
     "iopub.status.idle": "2025-06-13T13:03:09.278384Z",
     "shell.execute_reply": "2025-06-13T13:03:09.277944Z",
     "shell.execute_reply.started": "2025-06-13T13:03:08.400251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Re-tokenizing datasets with padding...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c76b2cddcd43778fdf91b89ed6dcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbbe86cda394cd28bd2e9a3237f77bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/141 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Padded tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Updated tokenization function with padding\n",
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "# Re-tokenize datasets with padding\n",
    "print(\"üîÑ Re-tokenizing datasets with padding...\")\n",
    "tokenized_train_dataset = train_set.map(generate_and_tokenize_prompt)\n",
    "tokenized_validation_dataset = validation_set.map(generate_and_tokenize_prompt)\n",
    "print(\"‚úÖ Padded tokenization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d083df12-6ab6-4f53-919a-cbcdaeb97cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:11.471383Z",
     "iopub.status.busy": "2025-06-13T13:03:11.470636Z",
     "iopub.status.idle": "2025-06-13T13:03:11.874041Z",
     "shell.execute_reply": "2025-06-13T13:03:11.873547Z",
     "shell.execute_reply.started": "2025-06-13T13:03:11.471347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Max token length: 257\n",
      "üìä Average token length: 257.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all tokens are now the same length\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed690f7-4fa9-41c1-b5a6-85e97d53854f",
   "metadata": {},
   "source": [
    "## Step 6: Configure QLoRA (Quantized LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9584f7e-4918-4382-827b-3996e5666303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:14.566845Z",
     "iopub.status.busy": "2025-06-13T13:03:14.566318Z",
     "iopub.status.idle": "2025-06-13T13:03:14.633939Z",
     "shell.execute_reply": "2025-06-13T13:03:14.633473Z",
     "shell.execute_reply.started": "2025-06-13T13:03:14.566829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Preparing model for QLoRA training...\n",
      "‚úÖ Model prepared for training!\n"
     ]
    }
   ],
   "source": [
    "# Prepare model for QLoRA fine-tuning\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "print(\"‚öôÔ∏è Preparing model for QLoRA training...\")\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(\"‚úÖ Model prepared for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca2da3ed-e9e9-4371-a695-40d98d34ce2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:16.841802Z",
     "iopub.status.busy": "2025-06-13T13:03:16.841129Z",
     "iopub.status.idle": "2025-06-13T13:03:16.844929Z",
     "shell.execute_reply": "2025-06-13T13:03:16.844500Z",
     "shell.execute_reply.started": "2025-06-13T13:03:16.841772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to check trainable parameters\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"üî¢ Trainable params: {trainable_params:,}\")\n",
    "    print(f\"üî¢ All params: {all_param:,}\")\n",
    "    print(f\"üìä Trainable%: {100 * trainable_params / all_param:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70eb4883-9d3a-451a-b3eb-d08b5163afd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:19.141719Z",
     "iopub.status.busy": "2025-06-13T13:03:19.141333Z",
     "iopub.status.idle": "2025-06-13T13:03:19.146276Z",
     "shell.execute_reply": "2025-06-13T13:03:19.145784Z",
     "shell.execute_reply.started": "2025-06-13T13:03:19.141701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Before QLoRA:\n",
      "üî¢ Trainable params: 0\n",
      "üî¢ All params: 12,457,497,600\n",
      "üìä Trainable%: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Check current trainable parameters (should be 0)\n",
    "print(\"üìã Before QLoRA:\")\n",
    "print_trainable_parameters(model)\n",
    "# print(model) #¬†optional, you can check the full architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7630da-021e-49cb-ab3a-9e79ca3f3009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:21.424091Z",
     "iopub.status.busy": "2025-06-13T13:03:21.423692Z",
     "iopub.status.idle": "2025-06-13T13:03:21.975221Z",
     "shell.execute_reply": "2025-06-13T13:03:21.974616Z",
     "shell.execute_reply.started": "2025-06-13T13:03:21.424074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Setting up LoRA configuration...\n",
      "‚úÖ LoRA adapters added!\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA adapters\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "print(\"üéØ Setting up LoRA configuration...\")\n",
    "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"]\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,                        # Rank of adaptation\n",
    "    lora_alpha=32,              # LoRA scaling parameter\n",
    "    target_modules=target_modules, \n",
    "    lora_dropout=0.05,          # Dropout probability for LoRA layers\n",
    "    bias=\"none\",                # Bias configuration\n",
    "    task_type=\"CAUSAL_LM\"       # Task type\n",
    ")\n",
    "\n",
    "# Apply LoRA to model\n",
    "model = get_peft_model(model, config)\n",
    "print(\"‚úÖ LoRA adapters added!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6977bef6-d2ab-4226-bcbc-9eff3775a82c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:24.562397Z",
     "iopub.status.busy": "2025-06-13T13:03:24.561694Z",
     "iopub.status.idle": "2025-06-13T13:03:24.570979Z",
     "shell.execute_reply": "2025-06-13T13:03:24.570469Z",
     "shell.execute_reply.started": "2025-06-13T13:03:24.562366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã After QLoRA:\n",
      "üî¢ Trainable params: 47,292,416\n",
      "üî¢ All params: 12,504,790,016\n",
      "üìä Trainable%: 0.38%\n"
     ]
    }
   ],
   "source": [
    "# Check trainable parameters after adding LoRA\n",
    "print(\"üìã After QLoRA:\")\n",
    "print_trainable_parameters(model)\n",
    "# print(model) #¬†optional, you can check the full architecture of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4407f94-6322-411d-9ee3-9830bb73b821",
   "metadata": {},
   "source": [
    "## Step 7: Fine-tuning Configuration & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b94d8a36-83f9-4fba-98e5-fa2269e6bc3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:28.673397Z",
     "iopub.status.busy": "2025-06-13T13:03:28.672582Z",
     "iopub.status.idle": "2025-06-13T13:03:28.676533Z",
     "shell.execute_reply": "2025-06-13T13:03:28.676135Z",
     "shell.execute_reply.started": "2025-06-13T13:03:28.673348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Enable model parallelism if multiple GPUs available\n",
    "dev_count = torch.cuda.device_count()\n",
    "print(f\"üñ•Ô∏è Available GPUs: {dev_count}\")\n",
    "\n",
    "if dev_count > 1:\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "    print(\"‚úÖ Model parallelism enabled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78fbb444-c1c9-4f08-88d2-4c5515f1635e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:32.807259Z",
     "iopub.status.busy": "2025-06-13T13:03:32.806867Z",
     "iopub.status.idle": "2025-06-13T13:03:32.859242Z",
     "shell.execute_reply": "2025-06-13T13:03:32.858513Z",
     "shell.execute_reply.started": "2025-06-13T13:03:32.807242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "import transformers\n",
    "\n",
    "# Set up logging directory\n",
    "log_bucket = \"./logs/medical-qlora-training\"\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=4,      # Batch size per device\n",
    "    per_device_eval_batch_size=4,       # Evaluation batch size\n",
    "    max_steps=20,                      # Total training steps\n",
    "    output_dir=\"mistral-medical-outputs\",  # Output directory\n",
    "    logging_dir=log_bucket,             # Logging directory\n",
    "    logging_steps=10,                   # Log every N steps\n",
    "    learning_rate=5e-6,                 # Learning rate\n",
    "    fp16=True,                          # Mixed precision training\n",
    "    save_strategy=\"steps\",              # Save strategy\n",
    "    save_steps=100,                     # Save every N steps\n",
    "    eval_strategy=\"steps\",              # Evaluation strategy\n",
    "    eval_steps=50,                      # Evaluate every N steps\n",
    "    do_eval=True,                       # Enable evaluation\n",
    "    warmup_steps=10,                    # Warmup steps\n",
    "    gradient_checkpointing=True,        # Memory optimization\n",
    "    gradient_accumulation_steps=4,      # Gradient accumulation\n",
    "    optim=\"paged_adamw_8bit\",          # Optimizer\n",
    "    report_to=\"tensorboard\",           # Logging platform\n",
    "    weight_decay=0.05                   # Regularization\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training configuration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f02e8c2-f7ad-4e31-98e7-d12665b350b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:35.605289Z",
     "iopub.status.busy": "2025-06-13T13:03:35.604488Z",
     "iopub.status.idle": "2025-06-13T13:03:36.163914Z",
     "shell.execute_reply": "2025-06-13T13:03:36.163494Z",
     "shell.execute_reply.started": "2025-06-13T13:03:35.605259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "# Disable caching for training\n",
    "model.config.use_cache = False\n",
    "\n",
    "print(\"‚úÖ Trainer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c339193-64e8-4ea8-ab06-95c97c1a21ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:03:39.038560Z",
     "iopub.status.busy": "2025-06-13T13:03:39.037826Z",
     "iopub.status.idle": "2025-06-13T13:14:30.912599Z",
     "shell.execute_reply": "2025-06-13T13:14:30.911837Z",
     "shell.execute_reply.started": "2025-06-13T13:03:39.038541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "‚è±Ô∏è This will take approximately 2-3 hours on ml.g6.12xlarge for 300 traninng steps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 10:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/peft/utils/save_and_load.py:220: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.6617823123931885, metrics={'train_runtime': 651.5031, 'train_samples_per_second': 0.491, 'train_steps_per_second': 0.031, 'total_flos': 1.132376062623744e+16, 'train_loss': 1.6617823123931885, 'epoch': 0.2826855123674912})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training!\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"‚è±Ô∏è This will take approximately 2-3 hours on ml.g6.12xlarge for 300 traninng steps\")\n",
    "\n",
    "# Uncomment the next line to start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdbf91-93be-44dc-ab29-8a86cf7c4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbe994-b101-4cb1-a98c-427790c0a9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef850cd8-3340-49d6-a7d9-b3ae00219cfc",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Model for Amazon Bedrock Custom Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4e296d-50a5-41e2-b035-ba2d0ed23eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:54.200276Z",
     "iopub.status.busy": "2025-06-13T13:58:54.200010Z",
     "iopub.status.idle": "2025-06-13T14:01:35.606529Z",
     "shell.execute_reply": "2025-06-13T14:01:35.606036Z",
     "shell.execute_reply.started": "2025-06-13T13:58:54.200261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:58:55.882273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749823135.893874    1475 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749823135.897410    1475 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-13 13:58:55.909797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e277ade5e4b24024b2ba02cbbfeddced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d22f7c73c24b968d5c4a90ed610a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/29.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cdb91952c0483a8b87b1bb56093a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff2fce4bc4b4e58b0321cc1cd6378f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682edba9f8984d6899b6ba4245c058a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a9fa541f744c7d88144891b306c919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7819f9d773c546aeac6261be39b06fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00010.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67fc4d3ae714f179c0f8bfab77f0cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6501e03f7e8543a59062f4c540d50286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe86e011104088a9d9f345ca1863d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00010.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2cf982cd814785bc3f64d04f25c65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f029cccf9028468eae60d169f9440776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00010.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199c1dd9a42d401788ac80b5c3fa1dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00010.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5658e80ed47bc81392672a9f42922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a0308859f64b6795e2761909d168f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "model_id = \"mistralai/Mistral-Small-24B-Instruct-2501\"\n",
    "adapter_path = \"mistral-medical-outputs/checkpoint-20\"\n",
    "\n",
    "# Load base model in full precision (FP16 or FP32)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"/mnt/sagemaker-nvme\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b03e8bd5-655a-4483-9324-09bd78b220a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:23:29.155983Z",
     "iopub.status.busy": "2025-06-13T13:23:29.155298Z",
     "iopub.status.idle": "2025-06-13T13:23:29.158635Z",
     "shell.execute_reply": "2025-06-13T13:23:29.158220Z",
     "shell.execute_reply.started": "2025-06-13T13:23:29.155949Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2173c0fb-ec7b-4ee2-81d7-e636dbfdf571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:54.148343Z",
     "iopub.status.busy": "2025-06-13T14:01:54.147902Z",
     "iopub.status.idle": "2025-06-13T14:02:24.783321Z",
     "shell.execute_reply": "2025-06-13T14:02:24.782801Z",
     "shell.execute_reply.started": "2025-06-13T14:01:54.148327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load fine-tuned model (with adapter)\n",
    "ft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c897e907-1040-4680-ba56-b51c0150fec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:02:24.784645Z",
     "iopub.status.busy": "2025-06-13T14:02:24.784306Z",
     "iopub.status.idle": "2025-06-13T14:02:25.600549Z",
     "shell.execute_reply": "2025-06-13T14:02:25.599990Z",
     "shell.execute_reply.started": "2025-06-13T14:02:24.784629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                             Size  Used Avail Use% Mounted on\n",
      "overlay                                 37G  5.3G   32G  15% /\n",
      "tmpfs                                   64M     0   64M   0% /dev\n",
      "tmpfs                                   61G     0   61G   0% /sys/fs/cgroup\n",
      "shm                                     16G   32K   16G   1% /dev/shm\n",
      "/dev/mapper/sagemaker_vg-sagemaker_lv  838G   50G  788G   6% /mnt/sagemaker-nvme\n",
      "/dev/nvme0n1p1                         180G   31G  150G  17% /usr/bin/nvidia-smi\n",
      "/dev/nvme3n1                           100G   51G   50G  51% /home/sagemaker-user\n",
      "127.0.0.1:/                            8.0E     0  8.0E   0% /mnt/custom-file-systems/efs/fs-09badb99b5c560bea_fsap-0c61ab2cee099341a\n",
      "tmpfs                                   61G   12K   61G   1% /proc/driver/nvidia\n",
      "tmpfs                                   61G  1.3M   61G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs                                   61G     0   61G   0% /proc/acpi\n",
      "tmpfs                                   61G     0   61G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a13abf-0ec0-4027-9cd9-dab0794db46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:03:14.337907Z",
     "iopub.status.busy": "2025-06-13T14:03:14.337465Z",
     "iopub.status.idle": "2025-06-13T14:04:38.249254Z",
     "shell.execute_reply": "2025-06-13T14:04:38.248849Z",
     "shell.execute_reply.started": "2025-06-13T14:03:14.337889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418cc412f2f348038e270bf58a7cf598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge LoRA weights into the base model\n",
    "merged_model = ft_model.merge_and_unload()\n",
    "\n",
    "# Save as FP16 (recommended for Bedrock)\n",
    "merged_model.save_pretrained(\"finetune_results/merged_model\", safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e09d5-0afb-400d-b5ae-c4f53ee5def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## optional: push your fine-tuned model to huggingface hub\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-Small-24B-Instruct-2501\")  # e.g., same tokenizer used during fine-tuning\n",
    "\n",
    "# # Push merged weights\n",
    "# merged_model.push_to_hub(\"ying2022/mistral-small-3-med\", use_temp_dir=False)\n",
    "\n",
    "# # Push tokenizer files too\n",
    "# tokenizer.push_to_hub(\"ying2022/mistral-small-3-med\", use_temp_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140b75fd-bacb-4db5-a08c-c3bc62fac31f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T14:59:31.384722Z",
     "iopub.status.busy": "2025-06-13T14:59:31.384290Z",
     "iopub.status.idle": "2025-06-13T14:59:31.750689Z",
     "shell.execute_reply": "2025-06-13T14:59:31.750293Z",
     "shell.execute_reply.started": "2025-06-13T14:59:31.384706Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f87f565e5b4091b75709b4f6d038f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5aa979b7264f14b0c0fd9f380d3afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model repo saved to: /home/sagemaker-user/workshop/fine-tuned-model\n"
     ]
    }
   ],
   "source": [
    "## download fine-tuned model from huggingface hub for the workshop\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "folder = snapshot_download(repo_id=\"ying2022/mistral-small-3-med\", local_dir=\"fine-tuned-model\")\n",
    "print(\"Model repo saved to:\", folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f547b-fad8-49df-bdb1-9303b4db71c5",
   "metadata": {},
   "source": [
    "### Upload model files to S3 bucket for CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbb5cf-0ceb-4886-a5c8-1e8457fecd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Configuration\n",
    "local_dir = \"fine-tuned-model\"\n",
    "bucket_name = \"3p-projects\"\n",
    "prefix = \"workshop/fine-tune/cmi\"  \n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Walk through local directory\n",
    "for root, dirs, files in os.walk(local_dir):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        # Compute relative path to preserve folder structure in S3\n",
    "        relative_path = os.path.relpath(local_path, local_dir)\n",
    "        s3_key = f\"{prefix}/{relative_path}\" if prefix else relative_path\n",
    "\n",
    "        print(f\"Uploading to s3://{bucket_name}/{s3_key}...\")\n",
    "        s3_client.upload_file(\n",
    "            Filename=local_path,\n",
    "            Bucket=bucket_name,\n",
    "            Key=s3_key\n",
    "        )\n",
    "        print(f\"Successfully transferred {local_path} to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d84b9e-a697-4755-8d8b-868374367ebb",
   "metadata": {},
   "source": [
    "### Create a CMI job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab2cd4-3c92-4fd0-b235-5c0d4df36cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "\n",
    "# 1Ô∏è‚É£ Initialize Bedrock client\n",
    "client = boto3.client(\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "# 2Ô∏è‚É£ Define your S3 model path and IAM role ARN\n",
    "s3_uri = f\"s3://{bucket_name}/{prefix}/\"\n",
    "role_arn = \"arn:aws:iam::123456789012:role/BedrockImportRole\" #¬†this need to be tested. create a new one? or execution role should work\n",
    "\n",
    "# 3Ô∏è‚É£ Create the import job\n",
    "response = client.create_model_import_job(\n",
    "    jobName = f\"mistral-small-3-import-{datetime.datetime.now():%Y%m%d%H%M%S}\",\n",
    "    importedModelName = \"mistral-small-3\",\n",
    "    roleArn = role_arn,\n",
    "    modelDataSource = {\n",
    "        \"s3DataSource\": {\n",
    "            \"s3Uri\": s3_uri\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Import job ARN:\", response[\"modelImportJobArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d956fb3-2224-4490-b898-9afae0c726d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623fdca-85ac-4122-8ffb-9638361be55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to use CMI model in Converse API? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f8448-f56d-4d9c-a94c-52dffbaebd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1526d705-6bc0-4864-a0e9-44dc5204269a",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c6dbe-5a3f-4b14-b4c2-4aa78fed8755",
   "metadata": {},
   "source": [
    "### Test mistral small 3.0 model before fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b90633f-fd1c-4345-a67c-324bcbbc467e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T14:26:36.296889Z",
     "iopub.status.busy": "2025-06-13T14:26:36.296021Z",
     "iopub.status.idle": "2025-06-13T14:27:05.725518Z",
     "shell.execute_reply": "2025-06-13T14:27:05.725028Z",
     "shell.execute_reply.started": "2025-06-13T14:26:36.296870Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, the patient's symptoms of fatigue, pallor, and pica, along with the laboratory findings of low mean corpuscular volume (MCV) and low ferritin levels, strongly suggest a diagnosis of iron deficiency anemia. Here are the potential diagnoses and next steps:\n",
      "\n",
      "### Potential Diagnoses:\n",
      "1. **Iron Deficiency Anemia**:\n",
      "   - **Symptoms**: Fatigue, pallor, pica (craving for non-food items like ice or dirt).\n",
      "   - **Laboratory Findings**: Low MCV (microcytic anemia), low ferritin, low serum iron, high total iron-binding capacity (TIBC).\n",
      "   - **Possible Causes**: Inadequate dietary intake, malabsorption, chronic blood loss (e.g., menstrual bleeding, gastrointestinal bleeding).\n",
      "\n",
      "2. **Thalassemia**:\n",
      "   - **Symptoms**: Can include fatigue, pallor.\n",
      "   - **Laboratory Findings**: Low MCV, normal or elevated hemoglobin A2, normal or slightly elevated ferritin.\n",
      "   - **Diagnosis**: Requires further genetic testing and hemoglobin electrophoresis.\n",
      "\n",
      "### Next Steps:\n",
      "1. **Detailed History**:\n",
      "   - Assess dietary intake of iron.\n",
      "   - Determine menstrual history and any history of gastrointestinal bleeding or other sources of chronic blood loss.\n",
      "   - Inquire about any history of gastrointestinal symptoms, such as diarrhea or abdominal pain, which may suggest malabsorption.\n",
      "\n",
      "2. **Further Laboratory Tests**:\n",
      "   - **Complete Blood Count (CBC)**: To confirm anemia and assess red blood cell indices.\n",
      "   - **Iron Studies**: Serum iron, TIBC, transferrin saturation, and ferritin.\n",
      "   - **Stool Test for Occult Blood**: To rule out gastrointestinal bleeding.\n",
      "   - **Hemoglobin Electrophoresis**: To evaluate for thalassemia if there is a suspicion based on family history or ethnicity.\n",
      "   - **Colonoscopy or Endoscopy**: If gastrointestinal bleeding is suspected.\n",
      "\n",
      "3. **Imaging Studies**:\n",
      "   - **Upper and Lower Endoscopy**: To identify sources of blood loss in the gastrointestinal tract.\n",
      "   - **Ultrasound or CT Scan**: To evaluate for other causes of anemia, such as tumors or other lesions.\n",
      "\n",
      "4. **Treatment**:\n",
      "   - **Oral Iron Supplementation**: If iron deficiency anemia is confirmed, start oral iron supplementation (e.g., ferrous sulfate).\n",
      "   - **Dietary Modifications**: Encourage a diet rich in iron, including red meat, poultry, fish, beans, and dark leafy vegetables.\n",
      "   - **Follow-Up**: Regular follow-up to monitor hemoglobin levels and iron stores, adjusting treatment as needed.\n",
      "\n",
      "5. **Referral**:\n",
      "   - **Gastroenterology**: If gastrointestinal bleeding is suspected.\n",
      "   - **Hematology**: If thalassemia or other hematologic disorders are suspected.\n",
      "\n",
      "By following these steps, you can accurately diagnose the underlying cause of the patient's anemia and implement appropriate treatment and management strategies.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-west-2')\n",
    "\n",
    "# Basic text generation\n",
    "def generate_text(prompt, model_id=\"arn:aws:sagemaker:us-west-2:459006231907:endpoint/endpoint-quick-start-o9v2c\"):\n",
    "  response = bedrock.converse(\n",
    "      modelId=model_id,\n",
    "      messages=[\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [{\"text\": prompt}]\n",
    "          }\n",
    "      ],\n",
    "      inferenceConfig={\n",
    "          \"maxTokens\": 1000,\n",
    "          \"temperature\": 0.7,\n",
    "          \"topP\": 0.9\n",
    "      }\n",
    "  )\n",
    "\n",
    "  return response['output']['message']['content'][0]['text']\n",
    "\n",
    "# Example usage\n",
    "prompt = \"\"\"A 32-year-old female presents with fatigue, pallor, and pica. \n",
    "Blood tests show a low mean corpuscular volume (MCV) and low ferritin levels. \n",
    "What are the potential diagnoses and next steps?\n",
    "\"\"\"\n",
    "result = generate_text(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec9fd1-ec63-4eeb-803e-9f8af4e530b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fine-tuned model from Bedrock CMI\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51019a-8e3e-444d-a247-1fc79e4dc805",
   "metadata": {},
   "source": [
    "## üéâ Workshop Complete!\n",
    "\n",
    "You've successfully learned how to:\n",
    "\n",
    "### ‚úÖ What You've Accomplished:\n",
    "1. **Set up** QLoRA fine-tuning environment\n",
    "2. **Loaded** and preprocessed medical training data\n",
    "3. **Configured** Mistral Small 24B with 4-bit quantization\n",
    "4. **Applied** LoRA adapters for efficient training\n",
    "5. **Understood** model preparation for Bedrock deployment\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- **Run the training**: Uncomment `trainer.train()` to start fine-tuning\n",
    "- **Test your model**: Compare base vs fine-tuned performance\n",
    "- **Deploy to Bedrock**: Use Custom Model Import for production\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [Amazon Bedrock Custom Model Import](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html)\n",
    "- [PEFT LoRA Documentation](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)\n",
    "- [Mistral AI Documentation](https://docs.mistral.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8144513-e6f9-419d-ad76-69cd2d0e9a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
